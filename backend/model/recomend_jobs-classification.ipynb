{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0709a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # Create TD / TF-IDF Matricies\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression # Preform Logistic Regression\n",
    "from sklearn.metrics import confusion_matrix # Make the Confustion Matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score # for AUC, fpr, tpr, threshold and accuracy\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from nltk.corpus import stopwords # for the Stopwords list\n",
    "from nltk.stem import PorterStemmer # for the porter Stemmer\n",
    "import nltk # for other nltk functions\n",
    "import re # for regular expression functions\n",
    "\n",
    "from tqdm import tqdm  # for progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "!pip install optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3e0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "job_postings = pd.read_csv(\"./postings.csv\")\n",
    "\n",
    "# Subsetting For Job Description and Experience Level\n",
    "want =  [\"description\",\"formatted_experience_level\"]\n",
    "df = job_postings[want]\n",
    "\n",
    "# Dropping Missing Values\n",
    "df = df.dropna(subset=['formatted_experience_level']).reset_index(drop=True)\n",
    "\n",
    "df['description'] = df['description'].astype(str)\n",
    "df[\"formatted_experience_level\"] = np.where(df[\"formatted_experience_level\"] == 'Entry level',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607287f",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5971c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Features(df, column_name):\n",
    "    feature_columns = ['word_cnt', 'sent_cnt', 'vocab_cnt', 'Avg_sent_word_cnt', 'lexical_richness','Readability_index']\n",
    "    feature_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row[column_name]\n",
    "\n",
    "        # Simple features (Word Count, Sentance Count, Vocabulary Count, Lexical Diversity)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        char_cnt = len(tokens)\n",
    "\n",
    "        words = [w for w in tokens if w.isalpha()]\n",
    "        word_cnt = len(words)\n",
    "\n",
    "        avg_word_length = char_cnt/word_cnt\n",
    "\n",
    "        sents = nltk.sent_tokenize(text)\n",
    "        sent_cnt = len(sents)\n",
    "\n",
    "        avg_sent_length = word_cnt / sent_cnt if sent_cnt > 0 else 0\n",
    "        avg_sent_length = round(avg_sent_length,2)\n",
    "\n",
    "        vocab = set(words)\n",
    "        vocab_cnt = len(vocab)\n",
    "\n",
    "        lex_richness = round(vocab_cnt / word_cnt, 4)\n",
    "\n",
    "        ARI = 4.71*avg_word_length + .5*avg_sent_length - 21.43\n",
    "\n",
    "        # Append the column data\n",
    "        feature_data.append([word_cnt, sent_cnt, vocab_cnt, avg_sent_length, lex_richness ,ARI]) # dropped avg_sent_length\n",
    "\n",
    "    feature_df = pd.DataFrame(feature_data, columns=feature_columns)\n",
    "\n",
    "    # Combine the original DataFrame with the new DataFrame containing features\n",
    "    result_df = pd.concat([df, feature_df], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d9d3c",
   "metadata": {},
   "source": [
    "### PreProcessing for Feature Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3e0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FE_df = Features(df,'description')\n",
    "FE_df['Cust_Service'] = FE_df['description'].apply(lambda x: 1 if 'customer service' in x.lower() else 0)\n",
    "FE_df['diploma_ged'] = FE_df['description'].apply(lambda x: 1 if 'diploma ged' in x.lower() else 0)\n",
    "FE_df['per_hour'] = FE_df['description'].apply(lambda x: 1 if 'per hour' in x.lower() else 0)\n",
    "FE_df['diploma_equiv'] = FE_df['description'].apply(lambda x: 1 if 'diploma equivalent' in x.lower() else 0)\n",
    "FE_df['project_management'] = FE_df['description'].apply(lambda x: 1 if 'project management' in x.lower() else 0)\n",
    "FE_df['cross_functional'] = FE_df['description'].apply(lambda x: 1 if 'cross functional' in x.lower() else 0)\n",
    "FE_df['minimum_years'] = FE_df['description'].apply(lambda x: 1 if 'minimum years' in x.lower() else 0)\n",
    "FE_df['experience_working'] = FE_df['description'].apply(lambda x: 1 if 'experience working' in x.lower() else 0)\n",
    "FE_df['management'] = FE_df['description'].apply(lambda x: 1 if 'management ' in x.lower() else 0)\n",
    "FE_df['track_record'] = FE_df['description'].apply(lambda x: 1 if 'track_record ' in x.lower() else 0)\n",
    "x_fe = FE_df.drop(['description', 'formatted_experience_level'], axis=1)\n",
    "y_fe = FE_df['formatted_experience_level']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_fe, y_fe, test_size = 0.2, random_state = 1)\n",
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train2, y_train2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_resampled_normalized = scaler.fit_transform(X_train_resampled)\n",
    "X_test2_normalized = scaler.transform(X_test2)\n",
    "\n",
    "X_train_resampled_normalized = pd.DataFrame(X_train_resampled_normalized, columns=X_train2.columns)\n",
    "X_test2_normalized = pd.DataFrame(X_test2_normalized, columns=X_test2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8942a5fd",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c96349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    C_value = trial.suggest_float('C', 1e-4, 1e3, log=True)  # Log-uniform distribution for C\n",
    "\n",
    "    logistic_fe = LogisticRegression(C=C_value, penalty='l1', solver='liblinear', max_iter=1000)\n",
    "    logistic_fe_cv_scores = cross_val_score(logistic_fe, X_train_resampled_normalized, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "    return logistic_fe_cv_scores.mean()\n",
    "\n",
    "start_time = time.time() # record time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "end_time = time.time() # record time\n",
    "#Computing Training Duration\n",
    "logistic_fe_tt = end_time - start_time\n",
    "\n",
    "print(f\"Train Time: {logistic_fe_tt} Seconds\")\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "mean_acc_lfe = study.best_value\n",
    "print(f\"Best 10-Fold CV Accuracy: {mean_acc_lfe:.2%}\")\n",
    "\n",
    "logistic_fe = LogisticRegression(C=best_params['C'], penalty='l1', solver='liblinear', max_iter=1000)\n",
    "logistic_fe.fit(X_train_resampled_normalized, y_train_resampled)\n",
    "\n",
    "# Predict on train and test datasets\n",
    "y_test_pred_lfe = logistic_fe.predict(X_test2_normalized)\n",
    "\n",
    "#Test Accuracy\n",
    "test_acc_lfe = accuracy_score(y_test2, y_test_pred_lfe)\n",
    "print(f\"Test Accuracy: {test_acc_lfe:.2%}\")\n",
    "\n",
    "print(\"Coefficient Weights on Test Data:\")\n",
    "coef_weights_test = logistic_fe.coef_\n",
    "for feature, coef in zip(X_train_resampled_normalized.columns, coef_weights_test.flatten()):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "# Compute test probabilities, false positive rate, true positive rate, and auc\n",
    "y_test_prob_lfe = logistic_fe.predict_proba(X_test2_normalized)[:, 1]  # Probability of class 1 (positive)\n",
    "fpr_lfe, tpr_lfe, threshold_lfe = roc_curve(y_test2,y_test_prob_lfe)\n",
    "auc_score_lfe = roc_auc_score(y_test2, y_test_prob_lfe)\n",
    "precision_lfe, recall_lfe, f1_lfe, _ = precision_recall_fscore_support(y_test2, y_test_pred_lfe)\n",
    "print(f\"AUC Score: {auc_score_lfe:.2%}\")\n",
    "print(f\"Precision: {precision_lfe[1]:.2%}\")\n",
    "print(f\"Recall: {recall_lfe[1]:.2%}\")\n",
    "print(f\"F1-Score: {f1_lfe[1]:.2%}\")\n",
    "\n",
    "# results\n",
    "# AUC Score: 68.66%\n",
    "# Precision: 52.04%\n",
    "# Recall: 66.57%\n",
    "# F1-Score: 58.41%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976654e8",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10b2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "start_time = time.time()\n",
    "# Fitting the Naive Bayes model\n",
    "bayes_fe = GaussianNB()\n",
    "# Preforming 10-Fold CV\n",
    "bayes_fe_10fold = cross_val_score(bayes_fe,X_train_resampled_normalized, y_train_resampled, cv=10)\n",
    "end_time = time.time()\n",
    "# Computing Train Time\n",
    "bayes_fe_tt = end_time - start_time\n",
    "print(f\"Training Duration: {bayes_fe_tt} Seconds\")\n",
    "\n",
    "mean_acc_bfe = bayes_fe_10fold.mean()\n",
    "print(f\"10-Fold Cross-Validation Accuracy: {mean_acc_bfe}\")\n",
    "\n",
    "bayes_fe.fit(X_train_resampled_normalized, y_train_resampled)\n",
    "# Predict on train and test datasets\n",
    "y_test_pred_bfe = bayes_fe.predict(X_test2_normalized)\n",
    "\n",
    "#Test Accuracy\n",
    "test_acc_bfe = accuracy_score(y_test2, y_test_pred_bfe)\n",
    "print(f\"Test Accuracy: {test_acc_bfe:.2%}\")\n",
    "\n",
    "# Compute test probabilities, false positive rate, true positive rate, and auc\n",
    "y_test_prob_bfe = bayes_fe.predict_proba(X_test2_normalized)[:, 1]  # Probability of class 1 (positive)\n",
    "fpr_bfe, tpr_bfe, threshold_bfe = roc_curve(y_test2,y_test_prob_bfe)\n",
    "auc_score_bfe = roc_auc_score(y_test2, y_test_prob_bfe)\n",
    "precision_bfe, recall_bfe, f1_bfe, _ = precision_recall_fscore_support(y_test2, y_test_pred_bfe)\n",
    "print(f\"AUC Score: {auc_score_bfe:.2%}\")\n",
    "print(f\"Precision: {precision_bfe[1]:.2%}\")\n",
    "print(f\"Recall: {recall_bfe[1]:.2%}\")\n",
    "print(f\"F1-Score: {f1_bfe[1]:.2%}\")\n",
    "\n",
    "#AUC Score: 66.13%\n",
    "#Precision: 66.37%\n",
    "#Recall: 6.93%\n",
    "#F1-Score: 12.55%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5c17f",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2c0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1, 20))\n",
    "cv_scores_fe = []\n",
    "\n",
    "start_time_knn = time.time()\n",
    "\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_model, X_train_resampled_normalized, y_train_resampled, cv=10)\n",
    "    cv_scores_fe.append(scores.mean())\n",
    "\n",
    "end_time_knn = time.time()\n",
    "knn_tt_fe1 = end_time_knn - start_time_knn\n",
    "\n",
    "errors_fe = [(1-i) for i in cv_scores_fe]\n",
    "\n",
    "figsize=(12, 6)\n",
    "plt.plot(k_values, errors_fe, marker='o')\n",
    "plt.title('KNN Error vs. Number of Neighbors (k)')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('10 Fold CV Error')\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal k with the highest accuracy\n",
    "optimal_k_fe = k_values[errors_fe.index(min(errors_fe))]\n",
    "print(f\"Optimal K: {optimal_k_fe}\")\n",
    "\n",
    "knn_fe = KNeighborsClassifier(n_neighbors=optimal_k_fe)\n",
    "start_time_knn = time.time()\n",
    "knn_10fold_fe = cross_val_score(knn_fe, X_train_resampled_normalized, y_train_resampled, cv=10)\n",
    "knn_fe.fit(X_train_resampled_normalized, y_train_resampled)\n",
    "end_time_knn = time.time()\n",
    "\n",
    "# Computing Training Duration\n",
    "knn_tt_fe = (end_time_knn - start_time_knn) + knn_tt_fe1\n",
    "print(f\"Training Duration: {knn_tt_fe} Seconds\")\n",
    "\n",
    "mean_acc_knnfe = knn_10fold_fe.mean()\n",
    "print(f\"10-Fold Cross-Validation Accuracy: {mean_acc_knnfe:.2%}\")\n",
    "\n",
    "#Training Duration: 487.02689814567566 Seconds\n",
    "#10-Fold Cross-Validation Accuracy: 81.09%\n",
    "\n",
    "# Predict on train and test datasets\n",
    "y_test_pred_knn_fe = knn_fe.predict(X_test2_normalized)\n",
    "\n",
    "# Test Accuracy\n",
    "test_acc_knn_fe = accuracy_score(y_test2, y_test_pred_knn_fe)\n",
    "print(f\"Test Accuracy: {test_acc_knn_fe:.2%}\")\n",
    "\n",
    "# Compute test probabilities, false positive rate, true positive rate, and auc\n",
    "y_test_prob_knn_fe = knn_fe.predict_proba(X_test2_normalized)[:, 1]  # Probability of class 1 (positive)\n",
    "fpr_knn_fe, tpr_knn_fe, threshold_knn_fe = roc_curve(y_test2, y_test_prob_knn_fe)\n",
    "auc_score_knn_fe = roc_auc_score(y_test2, y_test_prob_knn_fe)\n",
    "precision_knn_fe, recall_knn_fe, f1_knn_fe, _ = precision_recall_fscore_support(y_test2, y_test_pred_knn_fe)\n",
    "print(f\"AUC Score: {auc_score_knn_fe:.2%}\")\n",
    "print(f\"Precision: {precision_knn_fe[1]:.2%}\")\n",
    "print(f\"Recall: {recall_knn_fe[1]:.2%}\")\n",
    "print(f\"F1-Score: {f1_knn_fe[1]:.2%}\")\n",
    "#Test Accuracy: 71.20%\n",
    "#AUC Score: 69.82%\n",
    "#Precision: 63.62%\n",
    "#Recall: 63.26%\n",
    "#F1-Score: 63.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22632e81",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c83c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param_dist = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt',None]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2,20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1,20)\n",
    "    }\n",
    "\n",
    "    rf_fe = RandomForestClassifier(criterion='entropy', random_state=42, **param_dist)\n",
    "    cv_scores = cross_val_score(rf_fe, X_train_resampled_normalized, y_train_resampled, cv=10)\n",
    "\n",
    "    return cv_scores.mean()\n",
    "\n",
    "start_time = time.time() # record time\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective, n_trials=5)\n",
    "end_time = time.time() # record time\n",
    "\n",
    "#Computing Training Duration\n",
    "rf_fe_tt = end_time - start_time\n",
    "print(f\"Training Duration: {rf_fe_tt} Seconds\")\n",
    "print(\"Best Hyperparameters:\", study_rf.best_trial.params)\n",
    "mean_acc_rffe = study_rf.best_value\n",
    "print(f\"10-Fold Cross-Validation Accuracy: {mean_acc_rffe}\")\n",
    "#Training Duration: 5765.755069971085 Seconds\n",
    "#Best Hyperparameters: {'n_estimators': 326, 'max_features': None, 'min_samples_split': 14, 'min_samples_leaf': 7}\n",
    "#10-Fold Cross-Validation Accuracy: 0.7859696821921884\n",
    "\n",
    "# Best model from hyperparameter tuning\n",
    "rf_fe = RandomForestClassifier(criterion='entropy', random_state=42, **study_rf.best_trial.params)\n",
    "rf_fe.fit(X_train_resampled_normalized, y_train_resampled)\n",
    "\n",
    "# Predict on train and test datasets\n",
    "y_test_pred_rffe = rf_fe.predict(X_test2_normalized)\n",
    "\n",
    "#Test Accuracy\n",
    "test_acc_rffe = accuracy_score(y_test2, y_test_pred_rffe)\n",
    "print(f\"Test Accuracy: {test_acc_rffe:.2%}\")\n",
    "#Test Accuracy: 73.19%\n",
    "\n",
    "# Compute test probabilities, false positive rate, true positive rate, and auc\n",
    "y_test_prob_rffe = rf_fe.predict_proba(X_test2_normalized)[:, 1]  # Probability of class 1 (positive)\n",
    "fpr_rffe, tpr_rffe, threshold_rffe = roc_curve(y_test2, y_test_prob_rffe)\n",
    "auc_score_rffe = roc_auc_score(y_test2, y_test_prob_rffe)\n",
    "precision_rffe, recall_rffe, f1_rffe, _ = precision_recall_fscore_support(y_test2, y_test_pred_rffe)\n",
    "print(f\"AUC Score: {auc_score_rffe:.2%}\")\n",
    "print(f\"Precision: {precision_rffe[1]:.2%}\")\n",
    "print(f\"Recall: {recall_rffe[1]:.2%}\")\n",
    "print(f\"F1-Score: {f1_rffe[1]:.2%}\")\n",
    "\n",
    "# AUC Score: 79.75%\n",
    "# Precision: 66.31%\n",
    "# Recall: 65.28%\n",
    "# F1-Score: 65.79%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
